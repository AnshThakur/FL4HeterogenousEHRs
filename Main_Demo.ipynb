{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch\n",
    "from Model import GATT\n",
    "from loaders_FL import *\n",
    "from torch_geometric.nn.conv import GCN2Conv\n",
    "from utilsGHomo import *\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "from MakeGraph import MakegraphH\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "    \n",
    "random.seed(210)\n",
    "torch.manual_seed(210)\n",
    "np.random.seed(210)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get Data Loaders for CURIAL\n",
    "\n",
    "import pandas as pd\n",
    "A=pd.read_csv('./final_data/UHB.csv')\n",
    "columns2 = [col for col in A.columns if 'Blood_Test' in col]\n",
    "cols=columns2\n",
    "\n",
    "\n",
    "files=['BH','OUH','PUH','UHB']\n",
    "Loaders=get_loaders_structured(cols,files,path='./final_data/',batch=64,unstruct=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_device()\n",
    "print(f'Device: {device}')\n",
    "\n",
    "n_features = Loaders[0][0].dataset[0][0].shape[0]\n",
    "\n",
    "\n",
    "hidden_dim=128 \n",
    "in_dim=100 ### fixed dimension across clients after augmentation\n",
    "\n",
    "\n",
    "global_model= GATT(in_dim, hidden_dim,device)\n",
    "global_model.to(device)\n",
    "optimizer = torch.optim.Adam(params=global_model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "print(global_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#simulating client-side operation\n",
    "def client_training(global_weights, Loaders, client_id, inner_epochs=25, device=device):\n",
    "\n",
    "    ''' Function to train a client (by its client_id) \"locally\" given the global weights from the server '''\n",
    "    \n",
    "    train_loader = Loaders[client_id][0]\n",
    "\n",
    "    # Build the model (architecture only) locally and initialize is with the global weights\n",
    "    n_features = train_loader.dataset[0][0].shape[0]\n",
    "    # net= GAT(in_dim, hidden_dim,8)\n",
    "    # net = GCNT(in_dim, hidden_dim,device)\n",
    "    # net=Splinconv(in_dim, hidden_dim,device)\n",
    "    net = GATT(in_dim, hidden_dim,device)\n",
    "    # net= APPNPT(in_dim,hidden_dim,device)\n",
    "    net.to(device)\n",
    "    net.load_state_dict(global_weights)      \n",
    "    \n",
    "    # Initialise the local optimizer and store the initial weights\n",
    "    inner_opt = torch.optim.Adam(params=net.parameters(), lr=0.001)\n",
    "    inner_state = OrderedDict({k: tensor.data for k, tensor in global_weights.items()})\n",
    "    \n",
    "    # Initialize the local loss function\n",
    "    loss_fn = nn.BCELoss().to(device)\n",
    "    # loss_fcn = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    # Training loop for local training \n",
    "    train_loss = 0 \n",
    "    \n",
    "        \n",
    "    # Iterate over the batches in the dataloader\n",
    "    for i, batch in enumerate(train_loader):\n",
    "      inputs,label=batch\n",
    "\n",
    "      #************************************************************************\n",
    "      mean_original = inputs.mean()\n",
    "      std_dev_original = inputs.std()\n",
    "      normalized_data = (inputs - mean_original) / std_dev_original\n",
    "\n",
    "\n",
    "      indices = torch.randint(0, normalized_data.size(1), (in_dim-inputs.shape[1],))\n",
    "      resized_data = normalized_data[:, indices]\n",
    "\n",
    "      resized_data=torch.cat((inputs, resized_data),axis=1)\n",
    "      # print(resized_data.shape)\n",
    "      # # Transform back to original scale (optional)\n",
    "      # resized_transformed_data = (resized_data * std_dev_original) + mean_original\n",
    "      #************************************************************************\n",
    "\n",
    "\n",
    "    #   start = time.process_time()\n",
    "      g = MakegraphHT(resized_data)\n",
    "      # feature_transform = FeatureTransform(input_dim=inputs.shape[1], output_dim=16)  # Assume varying input_dim\n",
    "      \n",
    "      \n",
    "      # Move graph and features to device\n",
    "      g = g.to(device)\n",
    "      # transformed_features = feature_transform(g.x.float(),g.edge_index)      \n",
    "      for epoch in range(0, inner_epochs):\n",
    "            if i<len(train_loader)-1:\n",
    "              # print(i,len(train_loader))\n",
    "              # put model in train mode and reset the gradients to zero\n",
    "              net.train()\n",
    "              inner_opt.zero_grad()\n",
    "\n",
    "              # Forward pass\n",
    "              logits = net(g.edge_index, g.x.float())  # note that we pass edge_index and x (node features)\n",
    "              \n",
    "\n",
    "              # load data and labels\n",
    "            #   resized_data=resized_data.to(torch.float32).to(device)\n",
    "              label=label.to(torch.float32).to(device)\n",
    "\n",
    "\n",
    "              # print(logits)\n",
    "              # loss = loss_fn(logits.squeeze(1), label)\n",
    "              loss = loss_fn(logits, label)\n",
    "\n",
    "              # print(loss)\n",
    "              # backward pass to get gradients for optimization\n",
    "              loss.backward(retain_graph=True)\n",
    "\n",
    "\n",
    "              inner_opt.step()\n",
    "\n",
    "\n",
    "              train_loss += loss.detach().cpu().item() \n",
    "\n",
    "\n",
    "    # store gradients of client model after training\n",
    "    final_state = net.state_dict()\n",
    "\n",
    "    # calculate delta theta by subtracting the initial weight from the final weight\n",
    "    delta_theta = OrderedDict({k: inner_state[k] - final_state[k] for k in global_weights.keys()})\n",
    "    \n",
    "    av_train_loss = train_loss/len(train_loader)\n",
    "    return av_train_loss, delta_theta, net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = 'Ab'\n",
    "if not os.path.exists(f'./trained_models/{models_dir}'):\n",
    "    os.makedirs(f'./trained_models/{models_dir}')\n",
    "\n",
    "if not os.path.exists(f'./Dynamic/{models_dir}'):\n",
    "    os.makedirs(f'./Dynamic/{models_dir}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes=4\n",
    "# List for storing the metric dataframes for each client\n",
    "DF = [0]*nodes\n",
    "\n",
    "# List for best val auc at each client\n",
    "Val_AUC = [0]*nodes\n",
    "\n",
    "for h in range(0, nodes):\n",
    "    DF[h] = pd.DataFrame(columns=['Train_Loss', 'Val_Loss', 'Val_AUC'])\n",
    "\n",
    "loss_fn = nn.BCELoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### simulating server side\n",
    "\n",
    "num_rounds = 100\n",
    "for i in range(0, num_rounds):\n",
    "    print(f'------------------------------ STARTING TRAINING ROUND: {i+1} ... ---------------------------------') \n",
    "\n",
    "    # List to store the average client training loss after a round of training\n",
    "    TL = [0]*nodes\n",
    "    \n",
    "    # Put global model in training mode and get the weights which will be sent to the clients for local training\n",
    "    global_model.train()\n",
    "    optimizer.zero_grad()\n",
    "    global_weights = global_model.state_dict()\n",
    "\n",
    "    # List to store gradients from each client after a round of training \n",
    "    GRADS = [0]*nodes    \n",
    "    \n",
    "    # List to store the personalised models from each client\n",
    "    NETS = [0]*nodes\n",
    "\n",
    "    # Loop to iteratively train each client locally\n",
    "    for j in range(0, nodes):\n",
    "        TL[j], GRADS[j], NETS[j] = client_training(global_weights, Loaders, j, inner_epochs=1) \n",
    "        print(f'Node : {j}/{nodes} training complete...', end=\"\\r\") \n",
    "\n",
    "    # Combine the grads from each client after a round of local training across all clients to get the meta grad\n",
    "    grad = combine_grads(GRADS) \n",
    "\n",
    "    # Manually update the gradients of the global model parameters using the meta grad \n",
    "    for name, par in global_model.named_parameters():\n",
    "        if par.requires_grad:\n",
    "              par.grad = grad[name]\n",
    "    \n",
    "    # Update the global model parameters by optimizing using the meta grad for SGD\n",
    "    optimizer.step() \n",
    "\n",
    "    # Evaluate the global model (optimized using the meta gradient)\n",
    "    for k in range(0, nodes): \n",
    "        DF[k], Val_AUC[k] = evaluate_modelsT(k, Loaders, NETS[k], TL, loss_fn, device, DF[k], Val_AUC, models_dir)\n",
    "        print(f'Node : {k:.1f} || Val AUC {Val_AUC[k]:.4f}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating client-side personalised models \n",
    "for i in range(0, nodes): \n",
    "    # global_weights = global_model.load_state_dict(model)\n",
    "    model = torch.load(f'./trained_models/{models_dir}/node{i}')\n",
    "    # global_model.load_state_dict(model)\n",
    "\n",
    "    _, test_auc = prediction_binaryT(model, Loaders[i][2], loss_fn,device) \n",
    "    DF[i].to_csv(f'./Dynamic/{models_dir}/node{i}.csv') \n",
    "    \n",
    "    print(f'Node : {i:.1f} || Val AUC {Val_AUC[i]:.4f} || Test AUC {test_auc:.4f}') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
